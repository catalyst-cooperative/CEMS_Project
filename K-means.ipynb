{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas\n",
    "con = sqlite3.connect('coal.db')\n",
    "coal_labels = pandas.read_sql(\"select orispl_code, unitid, name, latitude, longitude, county, state, sum(CAST(gload as float)) as total_gen from data group by orispl_code, unitid\", con)\n",
    "con = sqlite3.connect('NG.db')\n",
    "NG_labels = pandas.read_sql(\"select orispl_code, unitid, name, latitude, longitude, county, state, sum(CAST(gload as float)) as total_gen from data group by orispl_code, unitid\", con)\n",
    "coal_labels.to_csv('coal_labels.csv')\n",
    "NG_labels.to_csv('NG_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "coal_labels = pandas.read_csv('coal_labels.csv')\n",
    "NG_labels = pandas.read_csv('NG_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: loading data\n",
    "import csv\n",
    "import numpy as np\n",
    "import os.path\n",
    "to_ml = []\n",
    "to_plot = []\n",
    "labels = []\n",
    "for i, row in coal_labels.iterrows():\n",
    "    for year in range(2001, 2017):\n",
    "        file_name = 'cf/' + str(row['orispl_code']) + '_' + row['unitid'] + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        with open(file_name, 'rb') as csvfile:\n",
    "            dr = csv.DictReader(csvfile)\n",
    "            to_insert = []\n",
    "            for row in dr:\n",
    "                to_insert.append(float( row['capacity_factor_hr'] if row['capacity_factor_hr'] is not '' else 0))\n",
    "                if int(row['']) % 24 is 23:\n",
    "                    to_plot.append(to_insert)\n",
    "                    to_ml.append(to_insert + np.gradient(to_insert).tolist())\n",
    "                    labels.append((row['op_date'], row['name'], row['unitid'], 'Coal'))\n",
    "                    to_insert = []\n",
    "import cPickle as pickle\n",
    "with open('labels.p', 'wb') as fp:\n",
    "    pickle.dump(labels, fp)\n",
    "with open('to_plot.p', 'wb') as fp:\n",
    "    pickle.dump(to_plot, fp)\n",
    "with open('to_ml.p', 'wb') as fp:\n",
    "    pickle.dump(to_ml, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "with open('labels.p', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "with open('to_plot.p', 'rb') as fp:\n",
    "    to_plot = pickle.load(fp)   \n",
    "with open('to_ml.p', 'rb') as fp:\n",
    "    to_ml = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8e98709a4a17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m24\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mto_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_insert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mto_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_insert\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_insert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'op_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unitid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Natural Gas'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mto_insert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os.path\n",
    "for i, row in NG_labels.iterrows():\n",
    "    for year in range(2001, 2017):\n",
    "        file_name = 'cf/' + str(row['orispl_code']) + '_' + row['unitid'].replace('*', '') + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        with open(file_name, 'rb') as csvfile:\n",
    "            dr = csv.DictReader(csvfile)\n",
    "            to_insert = []\n",
    "            for row in dr:\n",
    "                to_insert.append(float( row['capacity_factor_hr'] if row['capacity_factor_hr'] is not '' else 0))\n",
    "                if int(row['']) % 24 is 23:\n",
    "                    to_plot.append(to_insert)\n",
    "                    to_ml.append(to_insert + np.gradient(to_insert).tolist())\n",
    "                    labels.append((row['op_date'], row['name'], row['unitid'], 'Natural Gas'))\n",
    "                    to_insert = []\n",
    "import cPickle as pickle\n",
    "with open('labels.p', 'wb') as fp:\n",
    "    pickle.dump(labels, fp)\n",
    "with open('to_plot.p', 'wb') as fp:\n",
    "    pickle.dump(to_plot, fp)\n",
    "with open('to_ml.p', 'wb') as fp:\n",
    "    pickle.dump(to_ml, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets you pick up where you left off before - using stored labels and data and such\n",
    "import cPickle as pickle\n",
    "with open('labels.p', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "with open('to_plot.p', 'rb') as fp:\n",
    "    to_plot = pickle.load(fp)   \n",
    "with open('to_ml.p', 'rb') as fp:\n",
    "    to_ml = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: normalize data\n",
    "from sklearn.preprocessing import normalize\n",
    "normalized = normalize(to_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: run kmeans\n",
    "clusters = 20\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=clusters, random_state=0).fit(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os.path\n",
    "if os.path.exists('kmeans_' + str(clusters)):\n",
    "    shutil.rmtree('kmeans_' + str(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save images to inspect results\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "counts = clusters * [0]\n",
    "totals = clusters * [np.zeros(24)]\n",
    "for i in range(clusters):\n",
    "    if not os.path.exists('kmeans_' + str(clusters)+ '/' + str(i)):\n",
    "        os.makedirs('kmeans_' + str(clusters) + '/' + str(i))\n",
    "for i in range(len(normalized)):\n",
    "    counts[output[i]] += 1\n",
    "    totals[output[i]] = to_plot[i] + totals[output[i]]\n",
    "    # Sample .1% of days (~500 total) to verify that clusters are working \n",
    "    if random.randint(1, 1000) is not 100: continue\n",
    "    plt.gcf().clear()\n",
    "    plt.axis([0, 24, 0, 1])\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Capacity Factor')\n",
    "    plt.plot(to_plot[i])\n",
    "    plt.title(str(labels[i][1]) + \" unit \" + str(labels[i][2]) + \" operation on \" + str(labels[i][0]) + \" (\" + labels[i][3] + \")\")\n",
    "    plt.savefig('kmeans_' + str(clusters) + '/' + str(output[i]) + '/' + str(labels[i][1]) + '_' + str(labels[i][2]) + '_' + str(labels[i][0]) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(clusters):\n",
    "    values = totals[i] / counts[i]\n",
    "    plt.gcf().clear()\n",
    "    plt.axis([0, 24, 0, 1])\n",
    "    plt.plot(values)\n",
    "    plt.title(\"Cluster \" + str(i) + \" Average Shape\")\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Capacity Factor')\n",
    "    plt.savefig('kmeans_' + str(clusters) + '/average' + str(i) + \".png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(filename):\n",
    "    to_test = []\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        dr = csv.DictReader(csvfile)\n",
    "        to_insert = []\n",
    "        for row in dr:\n",
    "            to_insert.append(float(row['capacity_factor']))\n",
    "            if int(row['']) % 24 is 23:\n",
    "                to_test.append(to_insert + np.gradient(to_insert).tolist())\n",
    "                to_insert = []\n",
    "    if to_test == []: return clusters * [0]\n",
    "    result = kmeans.predict(normalize(to_test))\n",
    "    counts = clusters * [0]\n",
    "    for i in range(len(result)):\n",
    "        counts[result[i]] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_year(year):\n",
    "    to_test = []\n",
    "    for i, row in plant_labels.iterrows():\n",
    "        file_name = 'cf/' + str(row['orispl_code']) + '_' + row['unitid'] + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        with open(file_name, 'rb') as csvfile:\n",
    "            dr = csv.DictReader(csvfile)\n",
    "            to_insert = []\n",
    "            for row in dr:\n",
    "                to_insert.append(float( row['capacity_factor'] if row['capacity_factor'] is not '' else 0))\n",
    "                if int(row['']) % 24 is 23:\n",
    "                    to_test.append(to_insert + np.gradient(to_insert).tolist())\n",
    "                    to_insert = []\n",
    "    result = kmeans.predict(normalize(to_test))\n",
    "    counts = clusters * [0]\n",
    "    for i in range(len(result)):\n",
    "        counts[result[i]] += 1\n",
    "    return counts\n",
    "\n",
    "def get_plant_year(year, orispl_code):\n",
    "    to_test = []\n",
    "    unitids = []\n",
    "    for i, row in plant_labels.iterrows():\n",
    "        if row['orispl_code'] == orispl_code:\n",
    "            unitids.append(row['unitid'])\n",
    "    for unitid in unitids:\n",
    "        file_name = 'cf/' + str(orispl_code) + '_' + str(unitid) + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        with open(file_name, 'rb') as csvfile:\n",
    "            dr = csv.DictReader(csvfile)\n",
    "            to_insert = []\n",
    "            for row in dr:\n",
    "                to_insert.append(float( row['capacity_factor'] if row['capacity_factor'] is not '' else 0))\n",
    "                if int(row['']) % 24 is 23:\n",
    "                    to_test.append(to_insert + np.gradient(to_insert).tolist())\n",
    "                    to_insert = []\n",
    "    result = kmeans.predict(normalize(to_test))\n",
    "    counts = clusters * [0]\n",
    "    for i in range(len(result)):\n",
    "        counts[result[i]] += 1\n",
    "    return counts\n",
    "\n",
    "def get_unit_year(year, orispl_code, unitid):\n",
    "    return get_counts('cf/' + str(orispl_code) + '_' + str(unitid) + '_' + str(year) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261\n",
      "2517\n",
      "472\n",
      "191\n",
      "283\n",
      "1289\n",
      "223\n",
      "354\n",
      "282\n",
      "78\n",
      "2295\n",
      "1379\n",
      "317\n",
      "616\n",
      "1675\n",
      "36\n",
      "7891\n",
      "357\n",
      "9605\n",
      "218\n",
      "2665\n",
      "3446\n",
      "451\n",
      "185\n",
      "375\n",
      "631\n",
      "174\n",
      "330\n",
      "159\n",
      "70\n",
      "2241\n",
      "1313\n",
      "261\n",
      "507\n",
      "1707\n",
      "9\n",
      "8416\n",
      "324\n",
      "9934\n",
      "165\n",
      "3351\n",
      "4437\n",
      "995\n",
      "232\n",
      "411\n",
      "2420\n",
      "191\n",
      "501\n",
      "270\n",
      "110\n",
      "3602\n",
      "1183\n",
      "304\n",
      "846\n",
      "4661\n",
      "22\n",
      "5169\n",
      "405\n",
      "5542\n",
      "269\n",
      "2595\n",
      "6539\n",
      "2466\n",
      "418\n",
      "262\n",
      "1763\n",
      "137\n",
      "328\n",
      "81\n",
      "156\n",
      "2111\n",
      "1543\n",
      "256\n",
      "617\n",
      "2895\n",
      "15\n",
      "3676\n",
      "308\n",
      "4254\n",
      "386\n"
     ]
    }
   ],
   "source": [
    "code = 4941\n",
    "for year in [2001, 2006, 2011, 2016]:\n",
    "    for entry in get_year(year):\n",
    "        print entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535393\n"
     ]
    }
   ],
   "source": [
    "print len(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "37\n",
      "62\n",
      "10\n",
      "4\n",
      "0\n",
      "193\n",
      "1\n",
      "1\n",
      "1\n",
      "12\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "29\n",
      "32\n",
      "56\n",
      "5\n",
      "4\n",
      "0\n",
      "211\n",
      "0\n",
      "1\n",
      "6\n",
      "0\n",
      "3\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "71\n",
      "6\n",
      "53\n",
      "3\n",
      "8\n",
      "0\n",
      "166\n",
      "2\n",
      "6\n",
      "9\n",
      "15\n",
      "3\n",
      "10\n",
      "6\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "71\n",
      "33\n",
      "8\n",
      "62\n",
      "6\n",
      "1\n",
      "11\n",
      "12\n",
      "20\n",
      "20\n",
      "32\n",
      "4\n",
      "7\n",
      "11\n",
      "7\n",
      "8\n",
      "1\n",
      "50\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "code = 4941\n",
    "unitid = 3\n",
    "for year in [2001, 2006, 2011, 2016]:\n",
    "    for entry in get_unit_year(year, code, unitid):\n",
    "        print entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month_counts(filename):\n",
    "    to_test = {}\n",
    "    counts = {}\n",
    "    for month in range(1, 13):\n",
    "        to_test[month] = []\n",
    "        counts[month] = clusters * [0]\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        dr = csv.DictReader(csvfile)\n",
    "        to_insert = []\n",
    "        for row in dr:\n",
    "            to_insert.append(float(row['capacity_factor']))\n",
    "            if int(row['op_hour']) is 23:\n",
    "                month = int(row['op_date'][0:2])\n",
    "                to_test[month].append(to_insert + np.gradient(to_insert).tolist())\n",
    "                to_insert = []\n",
    "    for month in range(1, 13):\n",
    "        if to_test[month] == []: return counts\n",
    "        result = kmeans.predict(normalize(to_test[month]))\n",
    "        for i in range(len(result)):\n",
    "            counts[month][result[i]] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-82bcdd40b313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cf/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'orispl_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unitid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_month_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-73c4fa0119e8>\u001b[0m in \u001b[0;36mget_month_counts\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mto_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.pyc\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     X = check_array(X, sparse_format, copy=copy, warn_on_dtype=True,\n\u001b[1;32m-> 1344\u001b[1;33m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "for year in range(2002, 2017):\n",
    "    dictionary[year] = {}\n",
    "    for i, row in plant_labels.iterrows():\n",
    "        file_name = 'cf/' + str(row['orispl_code']) + '_' + str(row['unitid']) + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        counts = get_month_counts(file_name)\n",
    "        count = 0\n",
    "        for month in range(1, 13):\n",
    "            dictionary[year][month] = []\n",
    "            count += sum(counts[month])\n",
    "        if count is 0: continue\n",
    "        for month in range(1, 13):\n",
    "            percent = float(counts[month][6])/sum(counts[month])\n",
    "            dictionary[year][month].append(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'to_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7d3c048e912d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mto_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'to_test' is not defined"
     ]
    }
   ],
   "source": [
    "print month\n",
    "print to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 orispl_code    113\n",
      "unitid           1\n",
      "Name: 1, dtype: object\n",
      "2011 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2011 orispl_code    56319\n",
      "unitid           001\n",
      "Name: 99, dtype: object\n",
      "2011 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n",
      "2012 orispl_code    7504\n",
      "unitid          001\n",
      "Name: 80, dtype: object\n",
      "2012 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2012 orispl_code    56319\n",
      "unitid           001\n",
      "Name: 99, dtype: object\n",
      "2012 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n",
      "2013 orispl_code    6761\n",
      "unitid          101\n",
      "Name: 79, dtype: object\n",
      "2013 orispl_code    7504\n",
      "unitid          001\n",
      "Name: 80, dtype: object\n",
      "2013 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2013 orispl_code    56319\n",
      "unitid           001\n",
      "Name: 99, dtype: object\n",
      "2013 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n",
      "2013 orispl_code    56609\n",
      "unitid            01\n",
      "Name: 101, dtype: object\n",
      "2014 orispl_code    7504\n",
      "unitid          001\n",
      "Name: 80, dtype: object\n",
      "2014 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2014 orispl_code    56319\n",
      "unitid           001\n",
      "Name: 99, dtype: object\n",
      "2014 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n",
      "2014 orispl_code    56609\n",
      "unitid            01\n",
      "Name: 101, dtype: object\n",
      "2015 orispl_code    7504\n",
      "unitid          001\n",
      "Name: 80, dtype: object\n",
      "2015 orispl_code    8219\n",
      "unitid            1\n",
      "Name: 88, dtype: object\n",
      "2015 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2015 orispl_code    56319\n",
      "unitid           001\n",
      "Name: 99, dtype: object\n",
      "2015 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n",
      "2015 orispl_code    56609\n",
      "unitid            01\n",
      "Name: 101, dtype: object\n",
      "2016 orispl_code    50951\n",
      "unitid             1\n",
      "Name: 95, dtype: object\n",
      "2016 orispl_code    55479\n",
      "unitid           001\n",
      "Name: 96, dtype: object\n",
      "2016 orispl_code    56596\n",
      "unitid           001\n",
      "Name: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "for year in range(2001, 2017):\n",
    "    dictionary[year] =[]\n",
    "    for i, row in plant_labels.iterrows():\n",
    "        file_name = 'cf/' + str(row['orispl_code']) + '_' + str(row['unitid']) + '_' + str(year) + '.csv'\n",
    "        if not os.path.isfile(file_name): continue\n",
    "        counts = get_counts(file_name)\n",
    "        if sum(counts) == 0: continue\n",
    "        percent = float(counts[6])/sum(counts)\n",
    "        if percent > 0.7 and year > 2010:\n",
    "            print year, row\n",
    "        dictionary[year].append(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_csv = {}\n",
    "field_names = []\n",
    "field_names.append(\"Year\")\n",
    "for min_percentage in range(10):\n",
    "    field_names.append(str(float(min_percentage) / 10) + \" <= x < \" + str(float(min_percentage + 1) / 10))\n",
    "\n",
    "for year in dictionary:\n",
    "    to_csv[year] = {}\n",
    "    for min_percentage in range(10):\n",
    "        count = 0\n",
    "        for entry in dictionary[year]:\n",
    "            if entry >= float(min_percentage) / 10 and entry < float(min_percentage + 1) / 10:\n",
    "                count += 1\n",
    "        to_csv[year][field_names[min_percentage + 1]] = count\n",
    "    to_csv[year]['Year'] = year\n",
    "with open('percent_baseload.csv', 'wb') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    for year in to_csv:\n",
    "        writer.writerow(to_csv[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_labels = {}\n",
    "for year in [2001, 2006, 2011, 2016]:\n",
    "    year_labels[year] = pandas.read_sql(\"select orispl_code, unitid, name, latitude, longitude, county, state, sum(CAST(gload as float)) as total_gen from data where year is \" + str(year) + \" group by orispl_code, unitid\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a map visualization\n",
    "import csv\n",
    "fieldnames = ['Name', 'Unit ID', 'Latitude', 'Longitude', 'County', '% of days in baseload', 'Generation']\n",
    "for year in [2001, 2006, 2011, 2016]:\n",
    "    with open('k-means/baseload_map_' + str(year) + '.csv', 'wb') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i, row in year_labels[year].iterrows():\n",
    "            file_name = 'cf/' + str(row['orispl_code']) + '_' + str(row['unitid']) + '_' + str(year) + '.csv'\n",
    "            if not os.path.isfile(file_name): continue\n",
    "            counts = get_counts(file_name)\n",
    "            if sum(counts) == 0: continue\n",
    "            percent = float(counts[6])/sum(counts)\n",
    "            writer.writerow({'Name':row['name'], 'Unit ID':row['unitid'], 'Latitude':row['latitude'], 'Longitude': row['longitude'], 'County':row['county'] + \", \" + row['state'], '% of days in baseload': percent, 'Generation': row['total_gen']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
